# AUTOGENERATED! DO NOT EDIT! File to edit: 1. Pretrain BarlowTwins.ipynb (unless otherwise specified).

__all__ = ['get_dataloaders', 'train_model', 'push_vector', 'extract_features', 'calculate_bovw', 'plot_stats', 'train']

# Internal Cell
from fastcore.script import *
from fastai.vision.all import *
from self_supervised.augmentations import *
from self_supervised.layers import *
from self_supervised.vision.barlow_twins import *

try:
    import wandb
    from fastai.callback.wandb import *
except:
    wandb = False

# fixup depreciation
from kornia import augmentation as korniatfm
korniatfm.GaussianBlur = korniatfm.RandomGaussianBlur

# Cell
def get_dataloaders(path, size=224):
    fnames = get_image_files(path)
    dls = ImageDataLoaders.from_name_func(
        path, fnames,
        lambda x: False,
        item_tfms=RandomResizedCrop(size),
        valid_pct=0)

    return dls, dls.test_dl(fnames)

# Cell
def train_model(dls, samples=50000, size=224, backbone='resnet18', lr=5e-4, pretrained=True, preserve_colors=True):
    projection_size = 2048
    epochs = math.ceil(samples / len(dls.items))

    fastai_encoder = create_encoder(backbone, pretrained=pretrained)
    model = create_barlow_twins_model(fastai_encoder, projection_size=projection_size, hidden_size=projection_size)

    aug_pipelines = get_barlow_twins_aug_pipelines(size=size, bw=not preserve_colors, jitter=not preserve_colors)

    cbs = [BarlowTwins(aug_pipelines)]
    if wandb:
        cbs += [WandbCallback()]

    learn = Learner(dls, model, cbs=cbs)
    learn.fit_one_cycle(epochs, lr)

    return learn

# Cell
def push_vector(stack, vec):
    stack.append(vec)
    while len(stack) > 1 and len(stack[-1]) > len(stack[-2]):
        stack = stack[:-3] + torch.cat(stack[-2:])

def extract_features(test_dl, model):
    features = []
    with torch.no_grad():
        for (dx,) in progress_bar(test_dl):
            push_vector(features, model.encoder[:-3](dx).detach().cpu())
    raw_features = torch.cat(features).permute(0,2,3,1)
    print(raw_features.shape)
    return raw_features / torch.linalg.vector_norm(raw_features, dim=-1, keepdims=True)

# Cell
from sklearn.cluster import MiniBatchKMeans

def calculate_bovw(features, n_vwords=1024):
    print("Calculating KMeans:")
    kmeans = MiniBatchKMeans(n_clusters=n_vwords, verbose=1).fit(features.reshape(-1,256).cpu().numpy())
    vwords = kmeans.labels_.reshape(features.shape[:3])

    print("Calculating BoVW features:")
    bovw = np.zeros((len(features), n_vwords), dtype=np.uint8)
    for i in range(len(features)):
        bovw[i, np.unique(vwords[i])] = 1
    print(f"done ({bovw.shape})")
    return vwords, bovw

# Cell
def plot_stats(bovw):
    fig, axs = subplots(1, 2, figsize=(14,6))
    axs[0].set_title('Counts of photos containing each VWord')
    wpdf = bovw.sum(axis=0)
    axs[0].plot(wpdf[wpdf.argsort()[::-1]])
    axs[0].set_ylim(0,len(bovw))
    axs[1].set_title('Unique VWords per photo')
    wpdf = bovw.sum(axis=1)
    axs[1].plot(wpdf[wpdf.argsort()[::-1]])
    axs[1].set_ylim(0,196)
    return fig

# Cell
@call_parse
def train(
        path:Path, # directory containing all the images (we will find images in nested subdirectories)
        backbone:str    = 'resnet18', # backbone
        pretrained:bool = False, # use an ImageNet pretrained model as a starting point
        preserve_colors = True, # are colors important in your dataset (disables the B&W and color jitter augmentations)
        samples:int     = 50000, # how many samples to show to the model during training (default is 50k or the image count, whichever is higher)
        size:int        = 224, # the size of the image crops we train on
        n_vwords:int    = 1024, # how many visual-words to use for the Bag-of-Visual-Words representation
        lr:float        = 5e-4, # lr
        project:str     = None, # W&B project name
    ):
    "Pretrain a model on images in `path`."
    import wandb
    wandb.login()

    dls, test_dls = get_dataloaders(path, size)

    if project is None: project = f"{path.name}-mlqa-training"

    samples = math.ceil(samples / len(dls.items)) * len(dls.items)

    if wandb:
        run = wandb.init(project=project, config=dict(
            backbone=backbone, pretrained=pretrained,
            preserve_colors=preserve_colors,
            size=size, lr=lr, samples=samples))

    learn = train_model(dls, samples, size, backbone, lr, pretrained, preserve_colors)

    _pretrained = "-pretrained" if pretrained else ""
    _bw = "bw" if preserve_colors else ""
    name = f"mlqa-model-{backbone}{_pretrained}-{size}{_bw}x{samples}-lr{lr*1000}e-3"
    learn.save(name, with_opt=False)

    features = extract_features(test_dls, learn.model)

    _, bovw = calculate_bovw(features, n_vwords=n_vwords)

    stats_fname = path/'models'/'stats.png'
    plot_stats(bovw).savefig(stats_fname)

    np.savez_compressed(path/'models'/f'{name}-{n_vwords}vw.npz',
                       fnames = test_dls.items,
                       bovw = np.packbits(bovw, axis=1))

    if wandb:
        wandb.log({'VWords statistics': wandb.Image(str(stats_fname))})
        run.finish()