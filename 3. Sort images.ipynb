{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp sort_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa2acee",
   "metadata": {},
   "source": [
    "# Generate the JSON files with images sorted by similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastcore.script import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.wandb import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "from self_supervised.vision.barlow_twins import *\n",
    "\n",
    "# fixup depreciation\n",
    "from kornia import augmentation as korniatfm\n",
    "korniatfm.GaussianBlur = korniatfm.RandomGaussianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../women-in-tshirts-256/barlow-twins-resnet18-pretrained-224-5e-proj2048-lr0.5e-3-features.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202fd49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93dcd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9087])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x - features[remaining]).mean(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1464283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase([-0.0338, -0.0097,  0.0217,  ...,  0.0231, -0.0065, -0.0456])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ad3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random.choice(features)\n",
    "remaining = list(range(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba020e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(range(len(features))) - set(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ebbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def nn_sort(features):\n",
    "    x = random.choice(features)\n",
    "    remaining = list(range(len(features)))\n",
    "    idxs = []\n",
    "    while len(remaining):\n",
    "        i = torch.linalg.norm(x - features[remaining], dim=-1).argsort()[0]\n",
    "        idxs.append(remaining[i])\n",
    "        x = features[remaining[i]]\n",
    "        remaining.pop(i)\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def sort_images(\n",
    "        path:Path, # path\n",
    "        features_file:str = None # features file\n",
    "    ):\n",
    "    \"Pretrain a model on images in `path`.\"\n",
    "    if features_file is None:\n",
    "        ffiles = list(path.glob('*-features.pkl'))\n",
    "        if len(ffiles) == 0:\n",
    "            raise Exception(f\"No models found in: {path}!\")\n",
    "        elif len(ffiles) > 1:\n",
    "            msg = f\"Found multiple models in: {path}, please pass one of:\"\n",
    "            for file in ffiles:\n",
    "                msg += f\"\\n  --feature_file {file}\"\n",
    "            raise Exception(msg)\n",
    "        features_file = ffiles[0]\n",
    "        \n",
    "    with open(features_file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    fnames = data['fnames']\n",
    "    keyfunc = lambda x: fnames[x].parent\n",
    "    groups = [(name.name, list(group))\n",
    "              for name, group in itertools.groupby(sorted(range(len(fnames)), key=keyfunc), keyfunc)]\n",
    "    with open((path/Path(features_file).name.replace(\"-features\", \"-grouped\")).with_suffix('.json'), 'w') as f:\n",
    "        json.dump(dict(\n",
    "            dist_threshold = 1000,\n",
    "            labeled_clusters = [dict(\n",
    "                name = f\"{name} â€“ sorted perceptualy\",\n",
    "                photos = [dict(\n",
    "                    dist_to_mean=0, marked=False, murl=str(fnames[group[i]])\n",
    "                ) for i in nn_sort(data['features'][group])]\n",
    "            ) for name, group in groups]\n",
    "        ), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26419f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_images(Path('../women-in-tshirts-256/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
